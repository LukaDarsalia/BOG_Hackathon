{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow_hub as hub\n",
    "from langdetect import detect\n",
    "import google_transs\n",
    "import pickle\n",
    "import fasttext\n",
    "import re\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ელენე , შენ გამახსენდი და მაგარია\n"
     ]
    }
   ],
   "source": [
    "text = \"elene,შენ  გამახსენდი და მაგარია\"\n",
    "\n",
    "def linkRemoval(text):\n",
    "    if 'http' in text:\n",
    "        t = \"\"\n",
    "        s = -1\n",
    "        for i in range(0,len(text)):\n",
    "            if(s!=-1 and text[i]==' '):\n",
    "                s=-1  \n",
    "            if(i+3 < len(text)):\n",
    "                if(text[i]+text[i+1]+text[i+2]+text[i+3] == 'http'):\n",
    "                    s=i\n",
    "            if(s==-1):\n",
    "                t+=text[i]\n",
    "        text = t\n",
    "    return text\n",
    "\n",
    "def transLang(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        translator = google_transs.google_translator()\n",
    "        if(lang=='en' or lang=='ru' or lang=='pl' or lang=='uk'):\n",
    "            text = translator.translate(text, lang_tgt='ka')\n",
    "    except:\n",
    "        return text\n",
    "    return text\n",
    "    \n",
    "\n",
    "convertor = {\n",
    "    'a' : 'ა',\n",
    "    'b' : 'ბ',\n",
    "    'g' : 'გ',\n",
    "    'd' : 'დ',\n",
    "    'e' : 'ე',\n",
    "    'v' : 'ვ',\n",
    "    'z' : 'ზ',\n",
    "    'i' : 'ი',\n",
    "    'k' : 'კ',\n",
    "    'l' : 'ლ',\n",
    "    'm' : 'მ',\n",
    "    'n' : 'ნ',\n",
    "    'o' : 'ო',\n",
    "    'p' : 'პ',\n",
    "    'r' : 'რ',\n",
    "    's' : 'ს',\n",
    "    't' : 'ტ',\n",
    "    'u' : 'უ',\n",
    "    'f' : 'ფ',\n",
    "    'q' : 'კ',\n",
    "    'y' : 'ყ',\n",
    "    'sh': 'შ',\n",
    "    'ch': 'ჩ',\n",
    "    'ts': 'ც',\n",
    "    'c' : 'ც',\n",
    "    'dz': 'ძ',\n",
    "    'w' : 'ჭ',\n",
    "    'x' : 'ხ',\n",
    "    'j' : 'ჯ',\n",
    "    'h' : 'ჰ',\n",
    "}\n",
    "\n",
    "\n",
    "def isLatin(text):\n",
    "    latinWordCounter = 0\n",
    "    geoWordCounter = 0\n",
    "    for i in text:\n",
    "        if((i>'a' and i<'z') or (i>'A' and i<'Z')):\n",
    "            latinWordCounter += 1\n",
    "        if(i>'ა' and i<'ჰ'):\n",
    "            geoWordCounter += 1\n",
    "    return (latinWordCounter > geoWordCounter)\n",
    "\n",
    "def removeDuplicateLetters(text):\n",
    "    i=0\n",
    "    c=0\n",
    "    r=\"\"\n",
    "    while(i<len(text)):\n",
    "        if(i+1<len(text)):\n",
    "            if(text[i]==text[i+1]):\n",
    "                c+=1\n",
    "            else:\n",
    "                c=0\n",
    "        else:\n",
    "            c=0\n",
    "        if(c<1):\n",
    "            r+=text[i]\n",
    "        i+=1\n",
    "    return r\n",
    "\n",
    "def convertionLang(text):\n",
    "    text = linkRemoval(text)\n",
    "    text = transLang(text)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = cleanLatinText(text)\n",
    "    text = cleanGeoText(text)\n",
    "\n",
    "    text = removeDuplicateLetters(text)\n",
    "\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "\n",
    "def cleanGeoText(text):\n",
    "    res = ''\n",
    "    for i in text:\n",
    "        if(i=='თ'):\n",
    "            i='ტ'\n",
    "        elif(i=='წ'):\n",
    "            i='ჭ'\n",
    "        elif(i=='ჟ'):\n",
    "            i='ჯ'\n",
    "        elif(i=='ღ'):\n",
    "            i='გ'\n",
    "        elif(i=='ქ'):\n",
    "            i='კ'\n",
    "        res += i\n",
    "    return res\n",
    "\n",
    "\n",
    "def removeSuffix(text):\n",
    "    suffixes=['ები', 'ებო', 'ებს', 'ების', 'ებიტ', 'ტ', 'ტა', 'იანი', 'ოვანი', 'ედ', 'ტანა', 'ზე', 'ში']\n",
    "    sufArr = []\n",
    "    suf=\"\"\n",
    "\n",
    "    for i in range(0,min(5, len(text))):\n",
    "        suf=text[len(text)-i-1]+suf\n",
    "        sufArr.append(suf)\n",
    "    \n",
    "    for i in sufArr:\n",
    "        if i in suffixes:\n",
    "            text = text[0:len(text)-len(i)]\n",
    "            break\n",
    "    return text\n",
    "\n",
    "def removePrefix(text):\n",
    "    pass\n",
    "\n",
    "def seperateText(text):\n",
    "    t=\"\"\n",
    "    for i in range(0,len(text)):\n",
    "        if(text[i]<'ა' or text[i]>'ჰ'):\n",
    "            t+=' '\n",
    "            t+=text[i]\n",
    "            t+=' '\n",
    "        else:\n",
    "            t+=text[i]\n",
    "    return t\n",
    "\n",
    "def stemming(text):\n",
    "    text = seperateText(text)\n",
    "    textArr = text.split()\n",
    "    textArr = [removeSuffix(x) for x in textArr]\n",
    "    return ' '.join(textArr)\n",
    "\n",
    "\n",
    "def cleanLatinText(text):\n",
    "    res = ''\n",
    "    i=0\n",
    "    \n",
    "    while(i<len(text)):\n",
    "        c = text[i]\n",
    "        if(i+1 < len(text)):\n",
    "            n = text[i+1]\n",
    "            if(convertor.get(c+n) != None):\n",
    "                res+=convertor.get(c+n)\n",
    "                i+=1\n",
    "            elif(convertor.get(c) != None):\n",
    "                res+=convertor.get(c)\n",
    "            else:\n",
    "                res+=c\n",
    "        else:\n",
    "            if(convertor.get(c) != None):\n",
    "                res+=convertor.get(c)\n",
    "            else:\n",
    "                res+=c\n",
    "        i+=1\n",
    "    return res\n",
    "newText = convertionLang(text)\n",
    "print(newText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressBar(n,i):\n",
    "    sys.stdout.write('\\r')\n",
    "    j=(i+1)/n\n",
    "    # the exact output you're looking for:\n",
    "    sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(20*j), 100*j))\n",
    "    sys.stdout.flush()\n",
    "def convertData(dataName, saveName):\n",
    "    data = []\n",
    "    j=0\n",
    "    length = 0\n",
    "    with open(dataName, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        length = len(list(reader))\n",
    "\n",
    "    with open(dataName, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in enumerate(reader):\n",
    "            j+=1\n",
    "            if(line[0]==0): continue\n",
    "            progressBar(length, j-1)\n",
    "            tmp = [0, \"\", 0]\n",
    "            tmp[0] = line[1][1]\n",
    "            tmp[1] = convertionLang(line[1][2])\n",
    "            if(line[1][3]=='pos'): tmp[2]=0\n",
    "            if(line[1][3]=='neg'): tmp[2]=1\n",
    "            if(line[1][3]=='neu'): tmp[2]=2\n",
    "            data.append(tmp)\n",
    "    \n",
    "        print(\"Data Has been read and converted!\")\n",
    "        with open(saveName, 'wb') as ff:\n",
    "            pickle.dump(data, ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%Data Has been read and converted!\n"
     ]
    }
   ],
   "source": [
    "convertData(\"train_set.csv\", \"train_set_mod.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%Data Has been read and converted!\n"
     ]
    }
   ],
   "source": [
    "convertData(\"test_set.csv\", \"test_set_mod.pckl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31167', 'სიგუაც ზ უნდა დაგაყოლონ და სამივეს დედაუნდამოგიტყნა . არცერტი ხარ დასამარხი .', 0]\n",
      "['20647', 'რისტვის გაიმე ბიძაშვილი და ისიც გოგო ? გმერტმა ნატელ ამყოფოს', 1]\n"
     ]
    }
   ],
   "source": [
    "with open('train_set_mod.pckl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "\n",
    "with open('test_set_mod.pckl', 'rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "\n",
    "print(train_set[0])\n",
    "print(test_set[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `Y` for train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createY(dataset):\n",
    "    y=[]\n",
    "    for i in dataset:\n",
    "        tmp=[0,0,0]\n",
    "        n = int(i[2])\n",
    "        tmp[n]=1\n",
    "        y.append(tmp)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(createY(train_set))\n",
    "y_test  = np.array(createY(test_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `X` for train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX(dataset):\n",
    "    x=[]\n",
    "    for i in dataset:\n",
    "        x.append(i[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "სიგუაც ზ უნდა დაგაყოლონ და სამივეს დედაუნდამოგიტყნა . არცერტი ხარ დასამარხი .\n",
      "რისტვის გაიმე ბიძაშვილი და ისიც გოგო ? გმერტმა ნატელ ამყოფოს\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(createX(train_set))\n",
    "x_test  = np.array(createX(test_set))\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ელენე , შენ გამახსენდი . და მაგარია😀😀'"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replaceNums(s):\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' და ')\n",
    "    s = s.replace('@', ' ეთ ')\n",
    "    s = s.replace('0', ' ნული ')\n",
    "    s = s.replace('1', ' ერთი ')\n",
    "    s = s.replace('2', ' ორი ')\n",
    "    s = s.replace('3', ' სამი ')\n",
    "    s = s.replace('4', ' ოთხი ')\n",
    "    s = s.replace('5', ' ხუთი ')\n",
    "    s = s.replace('6', ' ექვსი ')\n",
    "    s = s.replace('7', ' შვიდი ')\n",
    "    s = s.replace('8', ' რვა ')\n",
    "    s = s.replace('9', ' ცხრა ')\n",
    "    return s\n",
    "replaceNums(\"ელენე , შენ გამახსენდი . და მაგარია😀😀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    }
   ],
   "source": [
    "def fasttextImplementation(dataset):\n",
    "    with open(\"comments_text.txt\" , 'w') as f:\n",
    "        length = len(dataset)\n",
    "        j=0\n",
    "        for i in dataset:\n",
    "            j+=1\n",
    "            progressBar(length, j)\n",
    "            f.write(replaceNums(i))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttextImplementation(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  10125\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   76460 lr:  0.000000 avg.loss:  7.821045 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "skipgram = fasttext.train_unsupervised(input=\"comments_text.txt\", model='skipgram', loss='hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.save_model('skipgram_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xMatrix(dataset):\n",
    "    x_train_mat = []\n",
    "    k=0\n",
    "    length = len(dataset)\n",
    "    for i in dataset:\n",
    "        k+=1\n",
    "        tmp = []\n",
    "        progressBar(length, k)\n",
    "        arr = i.split()\n",
    "        for j in arr:\n",
    "            tmp.append(skipgram.get_word_vector(j))\n",
    "        x_train_mat.append(np.array(tmp))\n",
    "    x_train_mat_1 = []\n",
    "    for i in x_train_mat:\n",
    "        x_train_mat_1.append(np.resize(i[:32],(32,100)))\n",
    "    return np.array(x_train_mat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mat_11=xMatrix(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 32, 100)"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mat_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_155\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_259 (InputLayer)         [(None, 32, 100)]    0           []                               \n",
      "                                                                                                  \n",
      " input_258 (InputLayer)         [(None, 32, 100)]    0           []                               \n",
      "                                                                                                  \n",
      " dense_271 (Dense)              (None, 32, 12)       1212        ['input_259[0][0]']              \n",
      "                                                                                                  \n",
      " dense_270 (Dense)              (None, 32, 12)       1212        ['input_258[0][0]']              \n",
      "                                                                                                  \n",
      " transformer_decoder_13 (Transf  (None, 32, 12)      17432       ['dense_271[0][0]',              \n",
      " ormerDecoder)                                                    'dense_270[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_25 (Flatten)           (None, 384)          0           ['transformer_decoder_13[0][0]'] \n",
      "                                                                                                  \n",
      " dense_272 (Dense)              (None, 3)            1155        ['flatten_25[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,011\n",
      "Trainable params: 21,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "450/450 [==============================] - 31s 36ms/step - loss: 0.4190 - accuracy: 0.7072 - val_loss: 0.3769 - val_accuracy: 0.7419\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 16s 36ms/step - loss: 0.3671 - accuracy: 0.7469 - val_loss: 0.3632 - val_accuracy: 0.7513\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 17s 37ms/step - loss: 0.3544 - accuracy: 0.7573 - val_loss: 0.3676 - val_accuracy: 0.7432\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 17s 37ms/step - loss: 0.3454 - accuracy: 0.7630 - val_loss: 0.3517 - val_accuracy: 0.7611\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 17s 38ms/step - loss: 0.3406 - accuracy: 0.7693 - val_loss: 0.3593 - val_accuracy: 0.7563\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 18s 41ms/step - loss: 0.3332 - accuracy: 0.7741 - val_loss: 0.3562 - val_accuracy: 0.7649\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 20s 44ms/step - loss: 0.3282 - accuracy: 0.7788 - val_loss: 0.3632 - val_accuracy: 0.7518\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 23s 51ms/step - loss: 0.3269 - accuracy: 0.7778 - val_loss: 0.3496 - val_accuracy: 0.7663\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 0.3208 - accuracy: 0.7827 - val_loss: 0.3473 - val_accuracy: 0.7672\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 18s 41ms/step - loss: 0.3170 - accuracy: 0.7862 - val_loss: 0.3541 - val_accuracy: 0.7714\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 20s 44ms/step - loss: 0.3157 - accuracy: 0.7873 - val_loss: 0.3503 - val_accuracy: 0.7615\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.3107 - accuracy: 0.7907 - val_loss: 0.3565 - val_accuracy: 0.7651\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 0.3076 - accuracy: 0.7937 - val_loss: 0.3639 - val_accuracy: 0.7585\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.3058 - accuracy: 0.7967 - val_loss: 0.3528 - val_accuracy: 0.7638\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 19s 42ms/step - loss: 0.3018 - accuracy: 0.7973 - val_loss: 0.3576 - val_accuracy: 0.7625\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 0.2985 - accuracy: 0.7999 - val_loss: 0.3574 - val_accuracy: 0.7592\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 22s 48ms/step - loss: 0.2958 - accuracy: 0.7999 - val_loss: 0.3600 - val_accuracy: 0.7601\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.2938 - accuracy: 0.8043 - val_loss: 0.3689 - val_accuracy: 0.7618\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 20s 45ms/step - loss: 0.2895 - accuracy: 0.8089 - val_loss: 0.3692 - val_accuracy: 0.7531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d880a90>"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = keras.Input(shape=(32, 100))\n",
    "decoder_input = keras.Input(shape=(32, 100))\n",
    "\n",
    "x=tf.keras.layers.Dense(12, activation=tf.keras.layers.LeakyReLU(alpha=0.1))(input)\n",
    "\n",
    "x_dec=tf.keras.layers.Dense(12, activation=tf.keras.layers.LeakyReLU(alpha=0.1))(decoder_input)\n",
    "\n",
    "decoder = keras_nlp.layers.TransformerDecoder(\n",
    "    intermediate_dim=512, num_heads=12)(x_dec, x)\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(decoder)\n",
    "output = layers.Dense(3, activation='softmax')(flat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[decoder_input, input], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, \\\n",
    "    restore_best_weights=True)]\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(\n",
    "    [x_train_mat_11,x_train_mat_11],\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    }
   ],
   "source": [
    "x_test_mat = xMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 32, 100)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 3s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict=model.predict([x_test_mat, x_test_mat], batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_predict, axis=1)\n",
    "y_test_arg=np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      3023\n",
      "           1       0.78      0.68      0.73      3018\n",
      "           2       0.69      0.72      0.71      2959\n",
      "\n",
      "    accuracy                           0.75      9000\n",
      "   macro avg       0.75      0.75      0.75      9000\n",
      "weighted avg       0.76      0.75      0.75      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_arg, y_pred_bool))\n",
    "# np.array(y_pred_bool).shape\n",
    "# y_pred_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customTest(custom_data_origin):\n",
    "    custom_data = [convertionLang(x) for x in custom_data_origin]\n",
    "    custom_data = xMatrix(custom_data)\n",
    "    y_pred = model.predict([custom_data, custom_data], batch_size=64, verbose=1)\n",
    "    y_pred_b = np.argmax(y_pred, axis=1)\n",
    "    results=[]\n",
    "    for i in range(0,len(custom_data_origin)):\n",
    "        results.append([custom_data_origin[i], y_pred_b[i]])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "[['genacvalet, gilocavt axal wels', 0]]\n"
     ]
    }
   ],
   "source": [
    "custom_data=['']\n",
    "print(customTest(custom_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%\n",
      "Data Has been read and converted!\n",
      "['5601486776576129_1450823435404030', 'გილოცავ მაგარია']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "j=0\n",
    "length = 0\n",
    "with open('processed_test_comments_formatted.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    length = len(list(reader))\n",
    "\n",
    "with open(\"processed_test_comments_formatted.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in enumerate(reader):\n",
    "        j+=1\n",
    "        if(line[0]==0): continue\n",
    "        progressBar(length, j-1)\n",
    "        tmp = [0, \"\"]\n",
    "        tmp[0] = line[1][0]\n",
    "        tmp[1] = convertionLang(line[1][4])\n",
    "        data.append(tmp)\n",
    "\n",
    "    print(\"\\nData Has been read and converted!\")\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_arr=[]\n",
    "for i in data:\n",
    "    id_arr.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "bog_sent=[]\n",
    "for i in data:\n",
    "    bog_sent.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    }
   ],
   "source": [
    "bog_sent = np.array(bog_sent)\n",
    "x_mat_bog = xMatrix(bog_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bogTest(bog_data, id_array):\n",
    "    \n",
    "    y_pred = model.predict([bog_data, bog_data], batch_size=64, verbose=1)\n",
    "    y_pred_b = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    results=[]\n",
    "    for i in range(0,len(id_array)):\n",
    "        results.append([id_array[i], y_pred_b[i]])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "results = bogTest(x_mat_bog, id_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5601486776576129_1450823435404030', 0]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bog_answers.csv', 'w') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow(['COMMENT_ID','SENTIMENT'])\n",
    "    for i in results:\n",
    "        wr.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "[=====================================================================================================================] 586%\n",
      "Data Has been read and converted!\n"
     ]
    }
   ],
   "source": [
    "newTrainX=[]\n",
    "with open('processed_train_comments_formatted.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    length = len(list(reader))\n",
    "    print(length)\n",
    "with open(\"processed_train_comments_formatted.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in enumerate(reader):\n",
    "        j+=1\n",
    "        if(line[0]==0): continue\n",
    "        progressBar(length, j-1)\n",
    "\n",
    "        newTrainX.append(convertionLang(line[1][4]))\n",
    "\n",
    "    print(\"\\nData Has been read and converted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['რამიყვარს კომფორტული სესხ 😀',\n",
       " 'ჩემი ბანკი ❤ ️ ❤ ️',\n",
       " 'უიუიუი',\n",
       " '❤ ️ ❤ ️ ❤ ️',\n",
       " '😍',\n",
       " 'ვერ ვიტან ამ ბანკს',\n",
       " 'ტყუილად ნუ ლაპარაკობ 1 5 ჭელია ამ ბანკტან მაკვს ურტიერტობა და როცა დამჯიტდა სესხი მაშინ ვერ გამოვიყენე მე მაჰალიტად ამ ბანკტან ყველანარი ურტიერტობას ვჭყვე და ჩემს მეგობრებსაც ვურჩევ რო ამ ბანკტან ტავი შორს დაიკავონ',\n",
       " 'ჩემი ჭკვ ❤ ️ მარა სად დაიკარგე კაცმა არ იცის 😃',\n",
       " 'აფიორა და ძარცვა ხალხის ეს ყველაფერი 😒',\n",
       " 'გამარტივდა კი 2 4 პროცენტ სამომხარებლო . ბანკი კი არა ჯოჯოხეტია',\n",
       " 'ბრავო 🥰 🇬 🇪 🇬 🇪 🇬 🇷',\n",
       " 'მაკედონია უტევდა . გოლ საკარტველოს სასარგებლოდ გავიტანე . გოლ',\n",
       " 'ჭარმატებ 🏆',\n",
       " 'გილოცავ',\n",
       " 'გილოცავ საკარტველო 🇬 🇪 ⚽ 🥇',\n",
       " 'ჭარმატებ',\n",
       " 'ჭარმატებ გილოცავ 👏 ✨ ♥ ️ ♥ ️ ♥ ️',\n",
       " 'აბა ფეხბურტის მაგინებლ სად არიან ეხლა . მოგებულსაც და ჭაგებულსაც ერტნაირად უნდა უგულშემატკივრო . ჭინ საკარტველო 😘',\n",
       " 'როგორ მიხარია ჭარმატებ',\n",
       " 'მაგარია',\n",
       " 'ბრაოი',\n",
       " 'გილოცავ ჩემო კვეყანა ❤ ️',\n",
       " 'ზივზივაძე მვპ',\n",
       " 'გილოცავ',\n",
       " '‼ ️ ❣ ️ ♥ ️ 👍 👌 👏 ♥ ️ ❣ ️ ‼ ️',\n",
       " '👏 🇬 🇪',\n",
       " '🧡',\n",
       " '🙏',\n",
       " '👏 🏼 ✊ 🏻 ✨ 😍 ❤ ️',\n",
       " '❤ ️',\n",
       " '👏 😘 🙏 ❤ ️',\n",
       " '👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽 👏 🏽',\n",
       " '👏 ❤ ️',\n",
       " '🤩 👏 🏻 👏 🏻',\n",
       " '👍',\n",
       " '👏 🏻 👏 🏻',\n",
       " '👏 🏼 👏 🏼 👏 🏼 👏 🏼 👏 🏼',\n",
       " '👏 🙏 ❤ ️ ❤ ️ ❤ ️',\n",
       " 'დაიჭყო საკარტველოს აგმავლობა გაბრჭყინებას ულოცავ ჩემს საკარტველოს .',\n",
       " 'საკარტველო პროჭი ბანი ტუა მანახე დგეს სესხის დგე მკონდა ტან დაბად დგე არ კი მომილოცეს ამ ნაბზრებმა აგენმა .',\n",
       " 'კი არ გავედი ვიყავი და ვარ პირველ',\n",
       " 'ჯერ ტურკეტს და მერე ყაზახეტი - საბერძნეტის გამარჯვებულს',\n",
       " 'მეორე გოლი გუნდური ტამაშის შედეგი იყო . ჭარმატებ საკარტველოს ნაკრ .',\n",
       " '⚽ ️ ⚽ ️ გილოცავ 🥳',\n",
       " 'მეგრელ როგორ უნდა გაკონდეს ყველაფერი 😂',\n",
       " 'გილიცავ ეს ერტი და სხვა მრავალი',\n",
       " 'საბერძნეტმა ვერ უნდა მოიგოს ორივე და ტურკეტს + 2 ბურტი უნდა ამოვუკაჩო და ტბილის იკნება პლეიფ ( ებ ) ი !',\n",
       " 'არის 2 გოლი ❤',\n",
       " 'ბუდუ საგოლ სული და გული დადო ❤ ️ ❤ ️ ❤ ️',\n",
       " 'ბრავო ბიჭ ! ⚽ ️ ⚽ ️ ⚽ ️ # არგაჩერდესაკარტველო ! 🇬 🇪 🇬 🇪 🇬 🇪',\n",
       " 'ყველა გული ეკუტვნის დგეს ბუდუ ზივზივაძეს ! ❤ ️',\n",
       " 'ზივზივაძეს ყოჩაგ , რა პასი მისცა .',\n",
       " 'ბრავო',\n",
       " 'ყველას მტელ გუნდს ყოჩაგ 🤗 ❤ კვარა ყოჩაგ',\n",
       " 'კაი რა ❤ ️ \\U0001faf6 🏻 ბრავო ✌ ️',\n",
       " 'როგორ გამიხარდა',\n",
       " 'ჩვენი ოკროს ბიჭი ♥ ️ ♥ ️',\n",
       " 'გოლ ბრავო 👏 🏻 👏 🏻 👏 🏻 ⚽',\n",
       " 'მაჩვენე რა მისი გოლი , გამომრჩა \\U0001fae3',\n",
       " 'კვარა ❤ ️',\n",
       " 'საკარტველოს სიამაყე ხარ 👌',\n",
       " 'საგოლ ძმა 👏',\n",
       " '❤ ️ ❤ ️ ❤ ️ ❤ ️ ❤ ️ გილოცავ',\n",
       " 'ჭარმატებ ჩვენს ბიჭ',\n",
       " 'ბრავო ❤ 👏',\n",
       " 'ეხცელენტე მი გეორგია ვამოს ა განარ ! ♥ ️ ♥ ️ ♥ ️',\n",
       " '⚽ 🧡',\n",
       " '⚽ 🙏',\n",
       " '🌟 ❤ ️ \\u200d 🔥 ❤ ️ \\u200d 🔥 \\U0001faf6 🏼',\n",
       " '👏 ❤ ️ ❤ ️ ❤ ️ ❤ ️ ❤ ️ ❤ ️ \\U0001faf6 🏻 \\U0001faf6 🏻 \\U0001faf6 🏻 \\U0001faf6 🏻 \\U0001faf6 🏻',\n",
       " '❤ 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 👏',\n",
       " '💓 🎊 💫',\n",
       " 'ეს ბიჭი გადაგვრევს ⚽ ️ ⚽ ️ ⚽ ️',\n",
       " 'ფეხბურტი კი არა კოლმეურნეობის ფილიალის კარი რატო არასდროს არ იგება ბანკომატან ჭვდომა რომ გვკონდეს ? ტუ სალონის ხარ და აგარ გჭირდება კარი',\n",
       " 'საკარტველოს ბანკი • ბანკ ოფ გეორგია საკარტველოს ბანკი დაცვას მიხედე , დაცვას 😉',\n",
       " 'გაიხარე ბიჭ',\n",
       " 'რაიო მეგრელ დისტანციურად მოვემსახურებიტო ?',\n",
       " 'საკარტველო პროჭი ბანი ტუა მანახე დგეს სესხის დგე მკონდა ტან დაბად დგე არ კი მომილოცეს ამ ნაბზრებმა აგენმა .',\n",
       " 'ლევანიკო 😂',\n",
       " 'არარის ეს ნორმალური 🙄',\n",
       " 'ბუდუ ზივძივაძის მასტერკლასი და კვარას გვირგვინი . 💪 ⚽ ️ 🥰',\n",
       " 'ყველას გილოცავ ამ გა . არჯვრბას 2 : 0 ძალიან მაგრ ხარ ვაჯკაც ვამაყობ ტკვენი',\n",
       " 'ბანკებიც მეგრელ გაკვ და გოლებიც 😁',\n",
       " 'მარგალეფ მანგარეფ',\n",
       " 'ფეხბურტის ყურებას ბანკის ფილიალ უყურო კამერა სალობიესავი ხან ვინ შემოგივარდება ხანვინ',\n",
       " '❤ ️ ❤ ️ ❤ ️ ❤ ️ ❤ ️ ❤ ️',\n",
       " 'ესენი კიდე მეგრელ ფოტოს რო აზიარ 😂',\n",
       " 'მალადეც ბიჭ ✊ 🙏',\n",
       " 'ბუდუ ზივზივაძე დგეს იყო ნომერ პირველი მოედან ❤',\n",
       " '🇬 🇪 🇬 🇪 🇬 🇪',\n",
       " '🏦 ბანკებიც მეგრელებმა უნდა გაიტანონ და გოლიც ⚽ ️ 😅 😂 🤌',\n",
       " '👏',\n",
       " 'გოლ ⚽ ️ ❤ ️ 💥',\n",
       " 'ხვიჩა - ჩა - ჩა - ჩა ჩაუტარა 😍',\n",
       " '🇬 🇪 ❤ ️',\n",
       " 'მგონი ეგირსა საკარტველის ფეხბურტს აგორძინება გაიხარე ბიჭ ჭარმატებჭბი',\n",
       " 'მორჩა კინო ! 🥱 ❤ ️ \\u200d 🔥 ❤ ️ \\u200d 🔥',\n",
       " 'ზივზივაძის დამსახურები კვარამ გაი 🤩',\n",
       " 'ისე მაკედონის დაცვის ხაზივი ხარ დაცულ ტკვენც 😂',\n",
       " '✔ ️ ერტხელ ხო მაინც უნდა გაგახარო მეგრელმა )',\n",
       " 'ის შესანიშნავი მოტამაშეა',\n",
       " 'გილოცავ , საკარტველო ! ❤',\n",
       " 'ამ ბიჯმა ფეხბურტის ყურება შემაყვარა ვამაყობ შენი საკარტვრლო 👌',\n",
       " 'მეკარე გვყავს მგელი 💙',\n",
       " 'უკვე 2 - 0 ვიგებ 👍 ❣',\n",
       " 'სუპერ ⚽ ჭარმატებ',\n",
       " '❤ ️',\n",
       " '❤ ️ ❤ ️ ❤ ️ ❤ ️ 👏',\n",
       " 'ისე ხაზარაძე გიგებ 2 - 0 🤣',\n",
       " '👏 👍 🇬 🇪 კარგია ესეტი რეკლამა აერტიან ერს 👍 ❤ ️',\n",
       " 'მჯერა რომ აუცილებლად მალე ასრულდება ჩვენი ოცნება 🇬 🇪 🇬 🇪 🇬 🇪',\n",
       " 'გამარჯვებას ვუსურვებ დგეს და ყოველტვის ჩემ საკარტველოს < 3',\n",
       " 'გულგრილად ვერ მოისმენს კაცი , ბრავო ვინც ამა იმუშავა 👏 👍',\n",
       " 'ჩემი ლუკაც მოხვდა ამ რეკლამა გილოცავ სიცოცხლე ჭარმატებ შენს არჩევან გისურვებდი დიდი ფეხბურტი გეტამაშლს საკარტველო გესახელებინოს .',\n",
       " 'კარგია გმადლობ',\n",
       " 'გმერტმა გისმინოს !',\n",
       " 'იმედი გაგვიჩნდა . კვარაცხელიას ტამაშმა , საერტიდ მისმა არსებობამ ფეხბურტის ონტერესი დამიბრუნა . ჭარმატებ ვუსურვებ მას და მტელ საკარტველოს ნაკრ . 😊 ❤ 🤩',\n",
       " 'რა მაგარია 🧡 მე მჯერა 🇬 🇪 ❤ ️',\n",
       " 'ფეხბურტი , მეტი ვიდრე სპორტი 🇬 🇪 ⚽ ❤ ️ 👌 მადლობა ტკვენ საკარტველოს ბანკი • ბანკ ოფ გეორგია 👏 საოცარი კადრ და სიტყვებია 👏 დიახ , ეს უზგვავი ემოცია . ⚽ 👌 დიახ , აკ ზომიერება ჭარმოუდგენელია 🇬 🇪 👌 დიახ , არასოდეს მინდა განვიკურნო . 🇬 🇪 ⚽ ❤ ️ 👌 მჯერა 🇬 🇪 ვიცი 🇬 🇪 ჩვენ შევძლებ 🇬 🇪 ეროვნული ნაკრ # მევარსაკარტველო 🇬 🇪 ⚽ ❤ ️ 👌',\n",
       " 'ასეც იკნება . საკსრტველო და კარტველი ხალხი ამას იმსახურ . გაბრჭყინდება საკარტველო და იკნება ყველგან და ყოველტვის გამარჯვებული და გაბრჭყინებული . ❤ 🇬 🇪 🇬 🇪 🇬 🇪 ❤',\n",
       " 'გაიხარე ამ რჭმენისტვის , ჩვენც გვჯერა , რომ ამას ჩვენი ბიჭ ბიჭ მალე სეძლებენ . იმედი არ მოგვიშალორ გმერტმა და მალე რეალობად გვიკციოს . 🙏',\n",
       " 'მე მჯერა . საკარტველოს გამარჯვ . კარტველ გამარჯვ . უფალი დამილოცე . 🙏 ჩემი საკარტველო . ჩემი კარტველნი . ბევრი გამარჯვება გველოდება . მე მჯერა . ❤ 🙏 ❤',\n",
       " 'გული ამიჩუყდა 🙄 😌 😍 🇬 🇪',\n",
       " 'რა სასიამოვნო მოსასმენი იყო ! მჯერა ! 👍 👏 💥',\n",
       " 'აბა . სი . გიჩკუ . კვარა ასახელი . მარგალეფი დო . საკორტუო კუგალე',\n",
       " 'ყველა გულშემატკივარის სულ ჩამჭვდომი სიტყვ ♥ ️ შესანიშნავი მუსიკის ფონ ♥ ️ ბევრი ჭარმატება ჩვენს სამშობლოს ♥ ️',\n",
       " 'კარგია და სიხარული ვიტირე ვერ შევიკავე ტავი გუშინ კი შიში იმედგაცრუებისა , ტამაშ ვერ უყურე , შემეშინდა . აი დგეს კი ვუყურებ უკვე დამშვიდებული , ჭარმატებ არ მოუშალოს ჩვენ ბიჭ , სპორტის ყველა სფერო . ოცნება რეალობი შეგვიცვალონ . მადლობა , მადლობა იხარე ერო შენი შვილები . გვიმრავლე და გბიდგეგრძელე .',\n",
       " 'კარგია ❤ ️ 👏 🇬 🇪 მადლობა . ♥ ️ ♥ ️ ♥ ️',\n",
       " 'გმერტი ამენ',\n",
       " 'г а м а р д ж в е б а с в у с у р в е б д г е с д а к о в е л т в и с',\n",
       " 'რა საიამოვნო მოსასმენი იყო ! მადლობა ! 💥 🇬 🇪 🙏',\n",
       " 'როგორც ყოველტვის ბრავო # საკარტველოსბანკი',\n",
       " 'სორდი დემნა მუჯგირ ადგილეფრე 😉',\n",
       " 'ჭარმატებ',\n",
       " 'ჭარმატებ გისურვებ .',\n",
       " 'გაიხარე ! კიდევ ბევრი აგმოჩენა !',\n",
       " 'ჭარმატებ არ დაგელიო ტკვენ პატრიოტო ადამიან .',\n",
       " 'ჭარმატებ . მრავალი აგმოჩენ ახლის .',\n",
       " 'ჭარმატებ ჩვენი კვეყნის არკეოლოგიას',\n",
       " 'ჩემი დმანისი',\n",
       " 'ჭარმატებ და ახალახალ საინტერესო აგმოჩენ გისურვებ',\n",
       " 'მაპატიე , მაგრამ სად მდებარეობს ოროზმანი ? ! 🤔',\n",
       " 'ნახე რა მაგრ ვარ',\n",
       " 'ჭარმატებ',\n",
       " 'სასიხარულოა ახალი აგმოჩენ საკარტველო უძველესი ჭვეყანა',\n",
       " '@',\n",
       " '. .',\n",
       " '🌹 🪴 🍷 🪴 🌹',\n",
       " '🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 👍 👏 💥 👏 👍 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪 🇬 🇪',\n",
       " '👏 👍',\n",
       " '👌',\n",
       " 'ჭარმატებ ჩვენს არკეოლოგ',\n",
       " '👍',\n",
       " 'საკარტველოს ბანკი არ გიტყდება რომ ტკვენი ფილიალ შეიარაგებული ყაჩაგ სანავარდო ადგილად იკცა ? მომხმარებლ რას ერჩი ?',\n",
       " 'ტკვენ დარვინიზმს ანვიტარებ გმერტმა ადამ შეკმნა ტავის სახიერი და არა მაიმუნის მაგვარი ტკვენ გვტის გმობა ხარ ჩარტული',\n",
       " 'მაინტერეს რამდენი ჭელი გავიდა მას შემდეგ რაც გმერტმა შეკმნა პირველი ჭყვილი და დედამიჭა დასახლა გასამრავლებად .',\n",
       " 'ადამის კბილიო _ არ მჯერა არანაირად',\n",
       " 'საკ ბანკი დედა მოგიტყან',\n",
       " 'ეს ადამ სამსახურიდან დასატხოვი იყო',\n",
       " 'იმედია ასაკი ახლა მაინც გავასჭრებ სომხ 😃 😄 😀 😁',\n",
       " 'ჭულუკიანს არ სცხვენია ახლა ?',\n",
       " 'კი ეგრეა მაგრამ ოკროს გული ჯვენი სახემძიბო ტუ ხკვია სახემჭიბო ანადგურ',\n",
       " 'ტკვე ჰემის 2 მილიონი ჭლის უკან კბილებსეძებ აგმოჰენ აკეტებ ეს ამდენი გაჰირვებული ხალხი ვერ აგმოაჰინე ?',\n",
       " 'იმ კარგმ - ულ პუტინს რომ ჰკიტხოსაკარტელო არ არსებობდაო მარტო რუსეატი არსებობდაო გაჭყდეს მტელი რუსეტი',\n",
       " 'პირველი ადამიან იყვნენ ადამი და ევა და აკამდე 7 0 ჭელიც არა ჯერ გასული',\n",
       " 'ვახ რა ეშველება საკრტველოს',\n",
       " 'ბაკი და ბანკირ 🤢',\n",
       " 'გაუმარტავი სისტემის მკონე ბანკი 👎',\n",
       " 'გამარჯობა მეგობრ ♥ ️ ასვლა , ცომ ეს არის ახალი ონლაინ კაზინოს საიტი სადაც ხალხის მოზიდვის მიზნი საჩუკრად იძლევიან 3 0 ფრესპინს სლოტ ზოდიაცო ჭჰელ ფრესპინ მიგებისტვის საჭიროა რეგისტრაცისას გამოიყენო ჩემი პრომო კოდი : ჯ 4 უ - 6 1 3 არ იტხოვს არანაირ ტანხის ჩარიცხვას და გატამაშებას ♥ ️',\n",
       " '👍',\n",
       " 'სომეხი სტომატოლოგის ამოგებულიაო ხომ არ იძახიან ჩვენი სომეხი ძმ 🤪',\n",
       " 'ყველაფერი გავიგე გარდა იმისა რომ აფრიკიდან აკ ჩამოსულან ადამიან . მაშინ როდესაც 1 . 8 მილიონი ჭლის ტავის კალ აკა აგმოჩენილი ხოლო აფრიკა რამდრნადაც ვიცი ყველა ძველი ტავის კალ 0 . 9 მილიონ ჭელს არ ცილდება რანაირად ჩამოვიდნენ ? . ანუ ტუ აკ აგმოაჩინეს 1 . 8 მილიონი ჭლის და იკ 0 . 9 მილიონი ჭლის იკიდან აკ როგორ ჩამოვიდნენ ?',\n",
       " 'და როგორ აფას ამ ნიჭიერი ხალხის გამოყრას სამსახურებიდან ? სანამდე ჭაუყრუებ ჭულუკიანის ასე მავნებლურ გამოხტომ ?',\n",
       " 'დაგლოცო უფალმა და გაგაძლიერო ძალიან საყვარელო არკეოლოგ ! 👍 🏻 😁 💗 ❤ 💚 დიდ ჭარმაყებეზს გისურვებ და უდიდეს მოტმინება - ამტანობას ! 😊 💝 💙 💞',\n",
       " 'ჩემი ბავშვობის აუხდენელი ოცნება 🥰',\n",
       " 'ტუკი ოდესმე რამე მიოცნებია , ეს ყველა დიდი ოცნება იყო , ალბა რომ ვერ ავიხდინე მაგიტომ . ყველა აგმოჩენა გული ისევ ისე აჩკარები მიცემს , როგორც 1 0 - 1 2 ჭლის ასაკ . მაშინაც და ახლაც ზგაპრულ და საოცარ აგმოჩენ ველოდ . ზუსტად ვიცი ჭინ კიდევ უამრავი გასაოცარი ამბავი გველოდება . ჭარმატებ და ასეტი დიდი შრომის დაფასება მინდა გისურვო . პ . ს . მოხალის ტუ გჭირდება დაჭერე , ვოცნებობ აკ ხალხი 😊',\n",
       " 'ისე საკარტველოს ბანკი ტუ დაფინანს რომელიმე ეკსპედიციას , კარგი იკნება .',\n",
       " 'და ასეტი ხალხი უ სამსახუროდ დატოვა კულტურის სამარცხვინო მინისტრმა 😡',\n",
       " '🙏 💖 🇬 🇪 ჭარმატებ ბატონ ბიძინაშვილს და მის ბრჭყინვალე გუნდს . ☝ ️ , ჭყალნი ჭავლენ და ჭამოვლენ , კვიშანი დარჩებიანო , ✊ ჭუნკლიანის ბოლო არ მეხარბება ნამდვილად 😡',\n",
       " \"ჭარმატებ და გამარჯვება ! , ბოროტსა სძლია კეტილმან , არსება მისი გრძელია ! '\",\n",
       " 'ჭარმატებ ჩემი ყველა საყვარელი პროფესია არკეოლოგია იყო და სამჭუხაროდ ოცნება ოცნებად დარჩა საოცარია საუკუნ ჭინანდელ ნაშტ ეხ მზის სინატლე გამოგაკვს ჭარმატებ ყველა ტკვენგანს',\n",
       " 'რა საინტერესოა , ჭარმატებ გისურვებ !',\n",
       " 'ჭარმატებ ჩვენს სამშობლოს ! ❤ ️ 💖 ❤ ️ 🇬 🇪 🇬 🇪 🇬 🇪 🙏',\n",
       " 'ლორეშიც ბევრ ისტორიას ვიპოვიდი როარ ჭაერტვა',\n",
       " 'სასიხარულოა ახალი აგმოჩენა , . არკეოლოგია ისტორია ძალიან მნიშვნელოვანია ჩვენს ცხოვრება',\n",
       " 'ჭულუკიანს , საკარტველოს ბანკმა დადოს სანკცია , რადგან ეგ ჭუნკალი ალკაჯი მტრობს იმ ხალხს , ვნც ამ ისტორიას ჭერს . ჭულუკ არის მავნებელი .',\n",
       " 'ალბა კბილის პატრონის ასაკიც გეცოდინება . 😆',\n",
       " 'ვაშა , მიხარია , ეს ამოჩენა მალე იკამდე მიგვიყვანს , რომ მეცნიერებმა ადამიანის განსახლ საჭყის ჭერტილად სამხრეტი კავკასია მიჩნიონ აფრიკის ნაცვლად . 😁 🥰 😁',\n",
       " 'აფრიკიდან კიარ მოვიდნენ . საკარტველოდან მოხდა ადანიან ჭასვლა სხვა ტერიტორიებ . სულ მოკლე ხან ნატელი იკნება ყველასატვის .',\n",
       " 'აბა ტკვენ იცი იკნებ საბოლოდ დამტკიცდეს კაცობრიობა ჩვენიდან გადასახლდა ყველგან მა შორის აფრიკა . ეხ',\n",
       " 'რატი გეიგე რამდენი ჭლისა კბილი ტავი ან გრანჭი სადგა',\n",
       " 'კიდევ ერტხელ დავრჭმუნდი რა მადლ კვეყნის შვილ ვარ და როგორ გაგვიმარტლა კარტველებად რომ გავჩნდი ამ კვეყნად . ჭარმატებ .',\n",
       " 'რომ უყურებ იმ დრო მაკან , რა საინტერესოა ჩვენი კვეყანა .',\n",
       " 'აფრიკიდან არ მოაულან ადამიან ! საკარტველოდან გავრცელდნენ ყველგან !',\n",
       " 'ვატყობ საკარტველო არკეოლოგიური აგმოჩენ ტავდაყირა დაყენ მსოფლიო ისტორია 😏',\n",
       " 'ჭარმატებ , ახალ - ახალი აგმოჩენ .',\n",
       " 'მშვენიერია ! ახლა მაინც გამოჩნდეს ინტელეკტული ადამიან !',\n",
       " 'ჭარმატებას გისურვებ',\n",
       " 'ბრჭყინვალე აგმოჩენა კიდევ მერამდენ ! უძველესი კულტურის ჭარმომადგენლობას დაემა მტკიცებულება ჩვენი ჭარმომავლობის უნიკალურობის შესახებ . ამას აგიარ მსოფლიო !',\n",
       " '👏',\n",
       " 'და საყდრისი აფეტკა ტკვენმა ერტერტმა , პატრონმა \"',\n",
       " 'ეს ყველაფერი კარგი მაგრამ ნამდვილ კრისტიანს არსჭამს ევკლუცის . კრისტიან გვჭამს რომ სიცოცხლე და ადამ გაჩინა ციცხალმა გმერტმა . დროა გვჭამდეს ის რაც ბიბლია ჭერია და დავიცვა მას ჩაჭერილი მცნებ . ეს გვიხსნის მხოლოდ უფლის მეორ მოსვლისას რომელიც ძალიან ახლისა !',\n",
       " 'ძალიან გტხოვ სომხ მოიჭვიე ტავის ჯურნალისტებიანა და აჩვენე და ტან ტავ ახლევინე ფაკტებ , ტორემ ჭაიგეს ტვინი',\n",
       " 'რა ბანკი ხალხნო აკ რაზეა საუბარი არ გაინტერსებ ? აკ საუბარია 1 . 8 მილიონი ჭლის ჭინანდელ ადამიან რომელიც საკარტველოს ტერიტორიაზეა ნაპოვნი და ესენი ჭერენ ვანკმა 2 ჭუტი გვიან გამომიგზავნა სმს _ ო 🤦 \\u200d ♂ ️',\n",
       " 'ვერ დავაგჭიო ტავი ჭარსულს , ჭინ ვერ ვუყურებ .',\n",
       " 'ველოდები სიახლ , ჭარმატებ 😍',\n",
       " 'ბანკი , რომელიც გადახდის დასადასტურებლად კოდს ვერ აგზავნის დროულად 🤦 \\u200d ♀ ️ 🤦 \\u200d ♀ ️',\n",
       " 'ჭარმატებები !',\n",
       " '. დაუსჭრებლად მიყვარხარ მომჭონს ტკენი შემარტება გფარავდე უფალი უანგარო პროფესისატვის',\n",
       " 'შენ ისევ იმ ა ხარ რომ აფრიკიდან მოვედი ? და ჩვენი უფრო ძველი რომა ?',\n",
       " 'მე მაკვს შაორის ხედი და ვტკბ რო ვუყურებ 😂 🤣 😂 🤣 აბა შაორი ? 🤷 \\u200d ♂ ️',\n",
       " 'სტუდენტურ განახლე',\n",
       " 'რა ლამაზი ხედებია \\U0001f979 და მე ოჩამჩირე რატომ დამიჭერე ? \\U0001f979',\n",
       " 'როგორ უნდა შევიძინო ეს ბარატი ? ჩემი გომის მ მინდა ❤',\n",
       " 'რა დაშავა აჭარამ ? რატომ დაგვიტოვე უბარატოდ . მე მომეჭონა ეს იდეა იგი გვიჩვენ ვინ რომელი კუტხის შვილია .',\n",
       " 'ჩემო ბუტკუნა აბა სენ იცი ჭარმატებ',\n",
       " 'კარგია',\n",
       " 'ბაკჰმარო არ არის ? 🙄',\n",
       " 'სცოლ ცარდ სად უნდა ვიგო ?',\n",
       " 'საკარტველოს ბანკი • ბანკ ოფ გეორგია , ძალიან მაგარ ვიდეო იგებ . ბრავო ! 👏 💖',\n",
       " 'მაგარი კურორტია .',\n",
       " '# დამინახე # მაგიარესტუდენტად # გსუ']"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTrainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "newTrainY=[]\n",
    "with open('newTrain.txt', 'r') as f:\n",
    "    while True:\n",
    "        score = f.readline()\n",
    "        if score == '': break\n",
    "        tmp=[0,0,0]\n",
    "        tmp[int(score)]=1\n",
    "        newTrainY.append(tmp)\n",
    "print(newTrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(222, 32, 100)"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_newTrain_mat = xMatrix(np.array(newTrainX))\n",
    "x_newTrain_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 6s 311ms/step - loss: 0.3168 - accuracy: 0.7740 - val_loss: 0.4887 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2701 - accuracy: 0.7853 - val_loss: 0.5381 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2537 - accuracy: 0.7853 - val_loss: 0.5810 - val_accuracy: 0.5778\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2457 - accuracy: 0.7910 - val_loss: 0.5517 - val_accuracy: 0.5778\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2233 - accuracy: 0.8136 - val_loss: 0.4879 - val_accuracy: 0.6000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2055 - accuracy: 0.8136 - val_loss: 0.4538 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2024 - accuracy: 0.8475 - val_loss: 0.4487 - val_accuracy: 0.6889\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1955 - accuracy: 0.8531 - val_loss: 0.4583 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1835 - accuracy: 0.8475 - val_loss: 0.4874 - val_accuracy: 0.6444\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1726 - accuracy: 0.8588 - val_loss: 0.5150 - val_accuracy: 0.6222\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1686 - accuracy: 0.8644 - val_loss: 0.5344 - val_accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1574 - accuracy: 0.8983 - val_loss: 0.5242 - val_accuracy: 0.6444\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1481 - accuracy: 0.9040 - val_loss: 0.5220 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1399 - accuracy: 0.9209 - val_loss: 0.5313 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1314 - accuracy: 0.9379 - val_loss: 0.5484 - val_accuracy: 0.6444\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1224 - accuracy: 0.9379 - val_loss: 0.5704 - val_accuracy: 0.6444\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1138 - accuracy: 0.9435 - val_loss: 0.5887 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183f72880>"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [x_newTrain_mat, x_newTrain_mat],\n",
    "    np.array(newTrainY),\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_v2\", 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    # pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
